{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "Copy of mlp_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfIRsbCDf4XE"
      },
      "source": [
        "# Training an MLP on MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou6kfQa_f4XN"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hEuK_Kef4XO"
      },
      "source": [
        "## Dataset manipulation\n",
        "\n",
        "1. Download the MNIST dataset contained in the files 'handwritten_digits_images.csv' and 'handwritten_digits_labels.csv'\n",
        "2. Write code that loads this dataset by storing images (represented as np.arrays) and labels in variables X and y respectively, then splits X and y into train/validation/test sets and finally saves the images in .jpeg or .png format following a specific hierarchy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AouwzgFOf4XP"
      },
      "source": [
        "#Get Data\n",
        "#Get Data\n",
        "X = pd.read_csv('handwritten_digits_images.csv', header=None).to_numpy()\n",
        "y = pd.read_csv('handwritten_digits_labels.csv', header=None).to_numpy()\n",
        "\n",
        "#Train-test-split\n",
        "seed = 42\n",
        "X_train, X_val_test, y_train, y_val_test = model_selection.train_test_split(X,y, test_size=0.2, shuffle=True, random_state=seed)\n",
        "seed = 123\n",
        "X_val, X_test, y_val, y_test = model_selection.train_test_split(X_val_test,y_val_test, test_size=0.5, shuffle=True, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZLjTnogf4XP"
      },
      "source": [
        "#Save as images\n",
        "if not os.path.exists('MNIST'):\n",
        "    os.mkdir('./MNIST')\n",
        "\n",
        "#save train dataset\n",
        "if not os.path.exists('MNIST/train'):\n",
        "    os.mkdir('./MNIST/train')\n",
        "for index, obj in enumerate(X_train):\n",
        "    obj_shape = np.reshape(obj, (28,28))\n",
        "    obj_shape = obj_shape.astype(np.uint8)\n",
        "    img = Image.fromarray(obj_shape, mode='L')\n",
        "    label_path = 'MNIST/train/' + str(y_train[index][0])\n",
        "    if not os.path.exists(label_path):\n",
        "        os.mkdir(label_path)\n",
        "    img.save(label_path + '/img' + str(index) + '.png', format='PNG')\n",
        "\n",
        "#save val dataset\n",
        "if not os.path.exists('MNIST/val'):\n",
        "    os.mkdir('./MNIST/val')\n",
        "for index, obj in enumerate(X_val):\n",
        "    obj_shape = np.reshape(obj, (28,28))\n",
        "    obj_shape = obj_shape.astype(np.uint8)\n",
        "    img = Image.fromarray(obj_shape, mode='L')\n",
        "    label_path = 'MNIST/val/' + str(y_val[index][0])\n",
        "    if not os.path.exists(label_path):\n",
        "        os.mkdir(label_path)\n",
        "    img.save(label_path + '/img' + str(index) + '.png', format='PNG')\n",
        "\n",
        "#save test dataset\n",
        "if not os.path.exists('MNIST/test'):\n",
        "    os.mkdir('./MNIST/test')\n",
        "for index, obj in enumerate(X_test):\n",
        "    obj_shape = np.reshape(obj, (28,28))\n",
        "    obj_shape = obj_shape.astype(np.uint8)\n",
        "    img = Image.fromarray(obj_shape, mode='L')\n",
        "    label_path = 'MNIST/test/' + str(y_test[index][0])\n",
        "    if not os.path.exists(label_path):\n",
        "        os.mkdir(label_path)\n",
        "    img.save(label_path + '/img' + str(index) + '.png', format='PNG')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OQx7SBjf4XQ"
      },
      "source": [
        "#define parameters for quick changes\n",
        "batch_size = 10\n",
        "learning_rate = .8\n",
        "epochs = 20\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#data preprocessor\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Pad(2, fill=0),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "#create the datasets\n",
        "train = torchvision.datasets.ImageFolder(root='./MNIST/train', transform=transform)\n",
        "test = torchvision.datasets.ImageFolder(root='./MNIST/test', transform=transform)\n",
        "val = torchvision.datasets.ImageFolder(root='./MNIST/val', transform=transform)\n",
        "\n",
        "#instantiate generators for the datasets\n",
        "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test, batch_size=1)\n",
        "valloader = torch.utils.data.DataLoader(val, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOgbPCaqf4XQ"
      },
      "source": [
        "6. In which context do we need data generators? How do data generators typically work?\n",
        "\n",
        "=> Data generators enable to automatically load the data in the form of batchesthat can be directly used for training/validation/testing. The format of the batches can vary and be manipulated in different ways. Usually data generators create a minibatch of the data and put them in a tensor. How the data is sampled into the batches can then be further defined with a sampler."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEatU-HBf4XR"
      },
      "source": [
        "## Write simple MLP and train it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0Dcxp9Nf4XR",
        "outputId": "d7a567c4-0dc4-40f7-c3a6-abf81a376360"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)\n",
        "\n",
        "#define MLP\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(1 * 32 * 32, 512),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(512,256),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(256,64),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(64,10),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "train_acc = np.array([])\n",
        "train_loss = np.array([])\n",
        "val_acc = np.array([])\n",
        "val_loss = np.array([])\n",
        "\n",
        "#training loop\n",
        "model = model.double()\n",
        "model.to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "  running_loss = .0\n",
        "  running_acc = .0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    model.train()\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = model(inputs.double())\n",
        "    loss = criterion(outputs.double(), labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # calculate running loss\n",
        "    running_loss += loss.item() * labels.size(0)\n",
        "    # calculate accuracy\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    # print every 500 mini-batches\n",
        "    if i % 500 == 499:\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "        (epoch + 1, i + 1, running_loss / total))\n",
        "      print('\\t   accuracy: %.2f %%' %((correct/total) * 100))\n",
        "  train_acc = np.append(train_acc, correct/total)\n",
        "  train_loss = np.append(train_loss, running_loss/total)\n",
        "\n",
        "  #get validarion accuracy\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  model.eval()\n",
        "  v_loss = .0\n",
        "  with torch.no_grad():\n",
        "    for data in valloader:\n",
        "      feature, labels = data[0].to(device), data[1].to(device)\n",
        "      val_output = model(feature.double())\n",
        "      v_loss += criterion(val_output.double(), labels).item() * labels.size(0)\n",
        "      _, predicted = torch.max(val_output.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  print('Evaluation on validation data: ')\n",
        "  print('Accuracy: %.2f %%' % (100 * correct / total))\n",
        "  print('Loss: %.3f' %(v_loss / total))\n",
        "  val_acc = np.append(val_acc, correct/total)\n",
        "  val_loss = np.append(val_loss, v_loss/total)\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "# test the network on the UNBIASED test data\n",
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "test_loss = .0\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    feature, labels = data[0].to(device), data[1].to(device)\n",
        "    test_output = model(feature.double())\n",
        "    test_loss += criterion(test_output.double(), labels).item() * labels.size(0)\n",
        "    _, predicted = torch.max(test_output.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print('Evalutation on test data: ')\n",
        "print('Accuracy: %.2f %%' % (100 * correct / total))\n",
        "print('Loss: %.3f' %(test_loss / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "[1,   500] loss: 2.305\n",
            "\t   accuracy: 9.62 %\n",
            "[1,  1000] loss: 2.303\n",
            "\t   accuracy: 10.39 %\n",
            "[1,  1500] loss: 2.303\n",
            "\t   accuracy: 10.69 %\n",
            "[1,  2000] loss: 2.302\n",
            "\t   accuracy: 10.96 %\n",
            "[1,  2500] loss: 2.302\n",
            "\t   accuracy: 10.98 %\n",
            "[1,  3000] loss: 2.297\n",
            "\t   accuracy: 11.41 %\n",
            "[1,  3500] loss: 2.284\n",
            "\t   accuracy: 12.95 %\n",
            "[1,  4000] loss: 2.265\n",
            "\t   accuracy: 15.19 %\n",
            "[1,  4500] loss: 2.248\n",
            "\t   accuracy: 17.29 %\n",
            "[1,  5000] loss: 2.231\n",
            "\t   accuracy: 19.27 %\n",
            "[1,  5500] loss: 2.215\n",
            "\t   accuracy: 21.17 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 43.07 %\n",
            "Loss: 2.031\n",
            "[2,   500] loss: 2.013\n",
            "\t   accuracy: 44.08 %\n",
            "[2,  1000] loss: 1.997\n",
            "\t   accuracy: 45.77 %\n",
            "[2,  1500] loss: 1.963\n",
            "\t   accuracy: 49.50 %\n",
            "[2,  2000] loss: 1.935\n",
            "\t   accuracy: 52.58 %\n",
            "[2,  2500] loss: 1.910\n",
            "\t   accuracy: 55.21 %\n",
            "[2,  3000] loss: 1.890\n",
            "\t   accuracy: 57.22 %\n",
            "[2,  3500] loss: 1.872\n",
            "\t   accuracy: 59.07 %\n",
            "[2,  4000] loss: 1.851\n",
            "\t   accuracy: 61.21 %\n",
            "[2,  4500] loss: 1.833\n",
            "\t   accuracy: 63.02 %\n",
            "[2,  5000] loss: 1.818\n",
            "\t   accuracy: 64.50 %\n",
            "[2,  5500] loss: 1.804\n",
            "\t   accuracy: 65.84 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 79.21 %\n",
            "Loss: 1.669\n",
            "[3,   500] loss: 1.657\n",
            "\t   accuracy: 80.58 %\n",
            "[3,  1000] loss: 1.660\n",
            "\t   accuracy: 80.15 %\n",
            "[3,  1500] loss: 1.658\n",
            "\t   accuracy: 80.39 %\n",
            "[3,  2000] loss: 1.657\n",
            "\t   accuracy: 80.49 %\n",
            "[3,  2500] loss: 1.655\n",
            "\t   accuracy: 80.72 %\n",
            "[3,  3000] loss: 1.655\n",
            "\t   accuracy: 80.71 %\n",
            "[3,  3500] loss: 1.654\n",
            "\t   accuracy: 80.77 %\n",
            "[3,  4000] loss: 1.653\n",
            "\t   accuracy: 80.83 %\n",
            "[3,  4500] loss: 1.653\n",
            "\t   accuracy: 80.87 %\n",
            "[3,  5000] loss: 1.651\n",
            "\t   accuracy: 81.06 %\n",
            "[3,  5500] loss: 1.650\n",
            "\t   accuracy: 81.12 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 81.83 %\n",
            "Loss: 1.643\n",
            "[4,   500] loss: 1.629\n",
            "\t   accuracy: 83.26 %\n",
            "[4,  1000] loss: 1.634\n",
            "\t   accuracy: 82.78 %\n",
            "[4,  1500] loss: 1.640\n",
            "\t   accuracy: 82.11 %\n",
            "[4,  2000] loss: 1.637\n",
            "\t   accuracy: 82.43 %\n",
            "[4,  2500] loss: 1.635\n",
            "\t   accuracy: 82.67 %\n",
            "[4,  3000] loss: 1.632\n",
            "\t   accuracy: 82.93 %\n",
            "[4,  3500] loss: 1.631\n",
            "\t   accuracy: 83.00 %\n",
            "[4,  4000] loss: 1.630\n",
            "\t   accuracy: 83.08 %\n",
            "[4,  4500] loss: 1.630\n",
            "\t   accuracy: 83.06 %\n",
            "[4,  5000] loss: 1.630\n",
            "\t   accuracy: 83.08 %\n",
            "[4,  5500] loss: 1.630\n",
            "\t   accuracy: 83.05 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 83.20 %\n",
            "Loss: 1.628\n",
            "[5,   500] loss: 1.620\n",
            "\t   accuracy: 84.18 %\n",
            "[5,  1000] loss: 1.618\n",
            "\t   accuracy: 84.32 %\n",
            "[5,  1500] loss: 1.617\n",
            "\t   accuracy: 84.35 %\n",
            "[5,  2000] loss: 1.618\n",
            "\t   accuracy: 84.34 %\n",
            "[5,  2500] loss: 1.619\n",
            "\t   accuracy: 84.18 %\n",
            "[5,  3000] loss: 1.621\n",
            "\t   accuracy: 84.00 %\n",
            "[5,  3500] loss: 1.621\n",
            "\t   accuracy: 83.95 %\n",
            "[5,  4000] loss: 1.622\n",
            "\t   accuracy: 83.89 %\n",
            "[5,  4500] loss: 1.621\n",
            "\t   accuracy: 84.04 %\n",
            "[5,  5000] loss: 1.620\n",
            "\t   accuracy: 84.07 %\n",
            "[5,  5500] loss: 1.620\n",
            "\t   accuracy: 84.08 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 84.37 %\n",
            "Loss: 1.617\n",
            "[6,   500] loss: 1.621\n",
            "\t   accuracy: 83.98 %\n",
            "[6,  1000] loss: 1.616\n",
            "\t   accuracy: 84.47 %\n",
            "[6,  1500] loss: 1.612\n",
            "\t   accuracy: 84.90 %\n",
            "[6,  2000] loss: 1.611\n",
            "\t   accuracy: 84.98 %\n",
            "[6,  2500] loss: 1.610\n",
            "\t   accuracy: 85.06 %\n",
            "[6,  3000] loss: 1.609\n",
            "\t   accuracy: 85.14 %\n",
            "[6,  3500] loss: 1.610\n",
            "\t   accuracy: 85.09 %\n",
            "[6,  4000] loss: 1.610\n",
            "\t   accuracy: 85.02 %\n",
            "[6,  4500] loss: 1.610\n",
            "\t   accuracy: 85.02 %\n",
            "[6,  5000] loss: 1.610\n",
            "\t   accuracy: 85.05 %\n",
            "[6,  5500] loss: 1.611\n",
            "\t   accuracy: 84.99 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 84.27 %\n",
            "Loss: 1.617\n",
            "[7,   500] loss: 1.608\n",
            "\t   accuracy: 85.36 %\n",
            "[7,  1000] loss: 1.606\n",
            "\t   accuracy: 85.47 %\n",
            "[7,  1500] loss: 1.606\n",
            "\t   accuracy: 85.46 %\n",
            "[7,  2000] loss: 1.604\n",
            "\t   accuracy: 85.70 %\n",
            "[7,  2500] loss: 1.590\n",
            "\t   accuracy: 87.13 %\n",
            "[7,  3000] loss: 1.582\n",
            "\t   accuracy: 88.04 %\n",
            "[7,  3500] loss: 1.574\n",
            "\t   accuracy: 88.77 %\n",
            "[7,  4000] loss: 1.569\n",
            "\t   accuracy: 89.34 %\n",
            "[7,  4500] loss: 1.564\n",
            "\t   accuracy: 89.83 %\n",
            "[7,  5000] loss: 1.560\n",
            "\t   accuracy: 90.25 %\n",
            "[7,  5500] loss: 1.556\n",
            "\t   accuracy: 90.60 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 93.41 %\n",
            "Loss: 1.529\n",
            "[8,   500] loss: 1.514\n",
            "\t   accuracy: 94.84 %\n",
            "[8,  1000] loss: 1.514\n",
            "\t   accuracy: 94.82 %\n",
            "[8,  1500] loss: 1.515\n",
            "\t   accuracy: 94.69 %\n",
            "[8,  2000] loss: 1.516\n",
            "\t   accuracy: 94.64 %\n",
            "[8,  2500] loss: 1.516\n",
            "\t   accuracy: 94.64 %\n",
            "[8,  3000] loss: 1.516\n",
            "\t   accuracy: 94.62 %\n",
            "[8,  3500] loss: 1.515\n",
            "\t   accuracy: 94.65 %\n",
            "[8,  4000] loss: 1.515\n",
            "\t   accuracy: 94.66 %\n",
            "[8,  4500] loss: 1.516\n",
            "\t   accuracy: 94.61 %\n",
            "[8,  5000] loss: 1.515\n",
            "\t   accuracy: 94.67 %\n",
            "[8,  5500] loss: 1.515\n",
            "\t   accuracy: 94.68 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 94.43 %\n",
            "Loss: 1.518\n",
            "[9,   500] loss: 1.515\n",
            "\t   accuracy: 94.60 %\n",
            "[9,  1000] loss: 1.508\n",
            "\t   accuracy: 95.34 %\n",
            "[9,  1500] loss: 1.508\n",
            "\t   accuracy: 95.34 %\n",
            "[9,  2000] loss: 1.508\n",
            "\t   accuracy: 95.34 %\n",
            "[9,  2500] loss: 1.507\n",
            "\t   accuracy: 95.48 %\n",
            "[9,  3000] loss: 1.508\n",
            "\t   accuracy: 95.32 %\n",
            "[9,  3500] loss: 1.509\n",
            "\t   accuracy: 95.27 %\n",
            "[9,  4000] loss: 1.509\n",
            "\t   accuracy: 95.28 %\n",
            "[9,  4500] loss: 1.508\n",
            "\t   accuracy: 95.31 %\n",
            "[9,  5000] loss: 1.508\n",
            "\t   accuracy: 95.30 %\n",
            "[9,  5500] loss: 1.508\n",
            "\t   accuracy: 95.34 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 94.87 %\n",
            "Loss: 1.514\n",
            "[10,   500] loss: 1.500\n",
            "\t   accuracy: 96.24 %\n",
            "[10,  1000] loss: 1.500\n",
            "\t   accuracy: 96.22 %\n",
            "[10,  1500] loss: 1.501\n",
            "\t   accuracy: 96.09 %\n",
            "[10,  2000] loss: 1.501\n",
            "\t   accuracy: 96.14 %\n",
            "[10,  2500] loss: 1.501\n",
            "\t   accuracy: 96.06 %\n",
            "[10,  3000] loss: 1.501\n",
            "\t   accuracy: 96.10 %\n",
            "[10,  3500] loss: 1.501\n",
            "\t   accuracy: 96.09 %\n",
            "[10,  4000] loss: 1.501\n",
            "\t   accuracy: 96.04 %\n",
            "[10,  4500] loss: 1.501\n",
            "\t   accuracy: 96.05 %\n",
            "[10,  5000] loss: 1.501\n",
            "\t   accuracy: 96.07 %\n",
            "[10,  5500] loss: 1.502\n",
            "\t   accuracy: 95.99 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 95.59 %\n",
            "Loss: 1.505\n",
            "[11,   500] loss: 1.495\n",
            "\t   accuracy: 96.72 %\n",
            "[11,  1000] loss: 1.496\n",
            "\t   accuracy: 96.57 %\n",
            "[11,  1500] loss: 1.495\n",
            "\t   accuracy: 96.59 %\n",
            "[11,  2000] loss: 1.497\n",
            "\t   accuracy: 96.42 %\n",
            "[11,  2500] loss: 1.497\n",
            "\t   accuracy: 96.43 %\n",
            "[11,  3000] loss: 1.498\n",
            "\t   accuracy: 96.38 %\n",
            "[11,  3500] loss: 1.497\n",
            "\t   accuracy: 96.44 %\n",
            "[11,  4000] loss: 1.497\n",
            "\t   accuracy: 96.43 %\n",
            "[11,  4500] loss: 1.497\n",
            "\t   accuracy: 96.42 %\n",
            "[11,  5000] loss: 1.497\n",
            "\t   accuracy: 96.40 %\n",
            "[11,  5500] loss: 1.498\n",
            "\t   accuracy: 96.39 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 95.36 %\n",
            "Loss: 1.508\n",
            "[12,   500] loss: 1.496\n",
            "\t   accuracy: 96.56 %\n",
            "[12,  1000] loss: 1.496\n",
            "\t   accuracy: 96.54 %\n",
            "[12,  1500] loss: 1.495\n",
            "\t   accuracy: 96.65 %\n",
            "[12,  2000] loss: 1.495\n",
            "\t   accuracy: 96.66 %\n",
            "[12,  2500] loss: 1.494\n",
            "\t   accuracy: 96.76 %\n",
            "[12,  3000] loss: 1.494\n",
            "\t   accuracy: 96.78 %\n",
            "[12,  3500] loss: 1.494\n",
            "\t   accuracy: 96.74 %\n",
            "[12,  4000] loss: 1.494\n",
            "\t   accuracy: 96.75 %\n",
            "[12,  4500] loss: 1.494\n",
            "\t   accuracy: 96.75 %\n",
            "[12,  5000] loss: 1.494\n",
            "\t   accuracy: 96.73 %\n",
            "[12,  5500] loss: 1.494\n",
            "\t   accuracy: 96.75 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 96.20 %\n",
            "Loss: 1.500\n",
            "[13,   500] loss: 1.494\n",
            "\t   accuracy: 96.66 %\n",
            "[13,  1000] loss: 1.493\n",
            "\t   accuracy: 96.84 %\n",
            "[13,  1500] loss: 1.492\n",
            "\t   accuracy: 96.94 %\n",
            "[13,  2000] loss: 1.492\n",
            "\t   accuracy: 96.96 %\n",
            "[13,  2500] loss: 1.492\n",
            "\t   accuracy: 96.95 %\n",
            "[13,  3000] loss: 1.492\n",
            "\t   accuracy: 96.98 %\n",
            "[13,  3500] loss: 1.492\n",
            "\t   accuracy: 97.01 %\n",
            "[13,  4000] loss: 1.491\n",
            "\t   accuracy: 97.02 %\n",
            "[13,  4500] loss: 1.492\n",
            "\t   accuracy: 96.96 %\n",
            "[13,  5000] loss: 1.492\n",
            "\t   accuracy: 96.98 %\n",
            "[13,  5500] loss: 1.492\n",
            "\t   accuracy: 96.95 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 94.01 %\n",
            "Loss: 1.521\n",
            "[14,   500] loss: 1.490\n",
            "\t   accuracy: 97.20 %\n",
            "[14,  1000] loss: 1.487\n",
            "\t   accuracy: 97.42 %\n",
            "[14,  1500] loss: 1.486\n",
            "\t   accuracy: 97.53 %\n",
            "[14,  2000] loss: 1.488\n",
            "\t   accuracy: 97.34 %\n",
            "[14,  2500] loss: 1.488\n",
            "\t   accuracy: 97.39 %\n",
            "[14,  3000] loss: 1.488\n",
            "\t   accuracy: 97.33 %\n",
            "[14,  3500] loss: 1.489\n",
            "\t   accuracy: 97.26 %\n",
            "[14,  4000] loss: 1.489\n",
            "\t   accuracy: 97.22 %\n",
            "[14,  4500] loss: 1.489\n",
            "\t   accuracy: 97.20 %\n",
            "[14,  5000] loss: 1.489\n",
            "\t   accuracy: 97.20 %\n",
            "[14,  5500] loss: 1.489\n",
            "\t   accuracy: 97.21 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 96.16 %\n",
            "Loss: 1.499\n",
            "[15,   500] loss: 1.490\n",
            "\t   accuracy: 97.16 %\n",
            "[15,  1000] loss: 1.487\n",
            "\t   accuracy: 97.45 %\n",
            "[15,  1500] loss: 1.487\n",
            "\t   accuracy: 97.36 %\n",
            "[15,  2000] loss: 1.487\n",
            "\t   accuracy: 97.43 %\n",
            "[15,  2500] loss: 1.487\n",
            "\t   accuracy: 97.44 %\n",
            "[15,  3000] loss: 1.487\n",
            "\t   accuracy: 97.47 %\n",
            "[15,  3500] loss: 1.487\n",
            "\t   accuracy: 97.45 %\n",
            "[15,  4000] loss: 1.487\n",
            "\t   accuracy: 97.43 %\n",
            "[15,  4500] loss: 1.487\n",
            "\t   accuracy: 97.45 %\n",
            "[15,  5000] loss: 1.487\n",
            "\t   accuracy: 97.44 %\n",
            "[15,  5500] loss: 1.487\n",
            "\t   accuracy: 97.45 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 96.51 %\n",
            "Loss: 1.496\n",
            "[16,   500] loss: 1.491\n",
            "\t   accuracy: 97.10 %\n",
            "[16,  1000] loss: 1.487\n",
            "\t   accuracy: 97.42 %\n",
            "[16,  1500] loss: 1.488\n",
            "\t   accuracy: 97.40 %\n",
            "[16,  2000] loss: 1.487\n",
            "\t   accuracy: 97.47 %\n",
            "[16,  2500] loss: 1.486\n",
            "\t   accuracy: 97.54 %\n",
            "[16,  3000] loss: 1.486\n",
            "\t   accuracy: 97.54 %\n",
            "[16,  3500] loss: 1.486\n",
            "\t   accuracy: 97.53 %\n",
            "[16,  4000] loss: 1.486\n",
            "\t   accuracy: 97.53 %\n",
            "[16,  4500] loss: 1.487\n",
            "\t   accuracy: 97.50 %\n",
            "[16,  5000] loss: 1.486\n",
            "\t   accuracy: 97.51 %\n",
            "[16,  5500] loss: 1.486\n",
            "\t   accuracy: 97.52 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 96.76 %\n",
            "Loss: 1.494\n",
            "[17,   500] loss: 1.485\n",
            "\t   accuracy: 97.68 %\n",
            "[17,  1000] loss: 1.484\n",
            "\t   accuracy: 97.71 %\n",
            "[17,  1500] loss: 1.484\n",
            "\t   accuracy: 97.73 %\n",
            "[17,  2000] loss: 1.485\n",
            "\t   accuracy: 97.67 %\n",
            "[17,  2500] loss: 1.484\n",
            "\t   accuracy: 97.72 %\n",
            "[17,  3000] loss: 1.484\n",
            "\t   accuracy: 97.78 %\n",
            "[17,  3500] loss: 1.484\n",
            "\t   accuracy: 97.74 %\n",
            "[17,  4000] loss: 1.484\n",
            "\t   accuracy: 97.75 %\n",
            "[17,  4500] loss: 1.484\n",
            "\t   accuracy: 97.74 %\n",
            "[17,  5000] loss: 1.484\n",
            "\t   accuracy: 97.75 %\n",
            "[17,  5500] loss: 1.484\n",
            "\t   accuracy: 97.74 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 96.29 %\n",
            "Loss: 1.499\n",
            "[18,   500] loss: 1.484\n",
            "\t   accuracy: 97.78 %\n",
            "[18,  1000] loss: 1.483\n",
            "\t   accuracy: 97.86 %\n",
            "[18,  1500] loss: 1.481\n",
            "\t   accuracy: 98.03 %\n",
            "[18,  2000] loss: 1.481\n",
            "\t   accuracy: 98.04 %\n",
            "[18,  2500] loss: 1.481\n",
            "\t   accuracy: 98.06 %\n",
            "[18,  3000] loss: 1.481\n",
            "\t   accuracy: 98.04 %\n",
            "[18,  3500] loss: 1.481\n",
            "\t   accuracy: 98.03 %\n",
            "[18,  4000] loss: 1.481\n",
            "\t   accuracy: 98.03 %\n",
            "[18,  4500] loss: 1.482\n",
            "\t   accuracy: 98.01 %\n",
            "[18,  5000] loss: 1.482\n",
            "\t   accuracy: 97.98 %\n",
            "[18,  5500] loss: 1.482\n",
            "\t   accuracy: 97.98 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 96.90 %\n",
            "Loss: 1.493\n",
            "[19,   500] loss: 1.484\n",
            "\t   accuracy: 97.76 %\n",
            "[19,  1000] loss: 1.482\n",
            "\t   accuracy: 98.00 %\n",
            "[19,  1500] loss: 1.481\n",
            "\t   accuracy: 98.12 %\n",
            "[19,  2000] loss: 1.480\n",
            "\t   accuracy: 98.11 %\n",
            "[19,  2500] loss: 1.481\n",
            "\t   accuracy: 98.07 %\n",
            "[19,  3000] loss: 1.481\n",
            "\t   accuracy: 98.07 %\n",
            "[19,  3500] loss: 1.481\n",
            "\t   accuracy: 98.07 %\n",
            "[19,  4000] loss: 1.480\n",
            "\t   accuracy: 98.11 %\n",
            "[19,  4500] loss: 1.480\n",
            "\t   accuracy: 98.12 %\n",
            "[19,  5000] loss: 1.481\n",
            "\t   accuracy: 98.07 %\n",
            "[19,  5500] loss: 1.481\n",
            "\t   accuracy: 98.07 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 96.80 %\n",
            "Loss: 1.493\n",
            "[20,   500] loss: 1.480\n",
            "\t   accuracy: 98.18 %\n",
            "[20,  1000] loss: 1.479\n",
            "\t   accuracy: 98.14 %\n",
            "[20,  1500] loss: 1.480\n",
            "\t   accuracy: 98.12 %\n",
            "[20,  2000] loss: 1.480\n",
            "\t   accuracy: 98.09 %\n",
            "[20,  2500] loss: 1.480\n",
            "\t   accuracy: 98.08 %\n",
            "[20,  3000] loss: 1.480\n",
            "\t   accuracy: 98.12 %\n",
            "[20,  3500] loss: 1.481\n",
            "\t   accuracy: 98.05 %\n",
            "[20,  4000] loss: 1.481\n",
            "\t   accuracy: 98.06 %\n",
            "[20,  4500] loss: 1.481\n",
            "\t   accuracy: 98.03 %\n",
            "[20,  5000] loss: 1.481\n",
            "\t   accuracy: 98.04 %\n",
            "[20,  5500] loss: 1.481\n",
            "\t   accuracy: 98.05 %\n",
            "Evaluation on validation data: \n",
            "Accuracy: 96.99 %\n",
            "Loss: 1.492\n",
            "Finished Training\n",
            "Evalutation on test data: \n",
            "Accuracy: 97.20 %\n",
            "Loss: 1.489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipqlToUEf4XT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "88a7bd8b-717e-454d-b43b-3ffddf5e20d8"
      },
      "source": [
        "#plot accuracies\r\n",
        "ep_range = np.arange(start=1, stop=epochs+1)\r\n",
        "plt.plot(ep_range, train_acc * 100, label='training accuracy')\r\n",
        "plt.plot(ep_range, val_acc * 100, label='validation accuracy')\r\n",
        "plt.legend()\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.title('Model accuracies')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "#plot loss\r\n",
        "plt.plot(ep_range, train_loss * 100, label='training loss')\r\n",
        "plt.plot(ep_range, val_loss * 100, label='validation loss')\r\n",
        "plt.legend()\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.title('Model loss')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYw4BwgQA94C"
      },
      "source": [
        "## Model description\r\n",
        "\r\n",
        "In the end the chosen model is a Neural Network with 4 hidden layers, each reducing the size of the input. It has 4 output neurons, one for each class of the dataset. This amount of layers makes the training time reasonable while yielding very good accuracies in a short amount of epochs.\r\n",
        "\r\n",
        "Looking at the plots of the training and validation loss, I would choose to train the final model for 8 epochs, as this amount has the best validation loss without overfitting on the training data. \r\n",
        "I trained for 20 epochs to log all the loss and accuracies and afterwards based on the plot choose the best configuration.\r\n",
        "\r\n",
        "The batch-size is set to 10 to speed up the process a little bit (vs having a batch-size of 1), but this parameter can still be improved for better performance, as 10 was just my first choice, which seemed to work out well.\r\n",
        "\r\n",
        "The learning rate is set at .8 to get good results relativeley quickly. I played around with the learning rate between .1 and 1 and .8 seems to be a good choice.\r\n",
        "\r\n",
        "All the hyperparameter choices are made by hand after running the model in different configurations and therefore not really optimized. It was enough to get the desired accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK8Uji9qeZ5Z"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}